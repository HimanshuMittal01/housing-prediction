{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Housing Prediction\n",
    "\n",
    "The goal of this task is to use web scraping and apply decision tree models to predict housing prices based on scraped data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "\n",
    "- Select a city of your choice for which you will scrape housing data. Examples include Chicago, New York, San Francisco, etc.\n",
    "- Use web scraping tools to collect housing data from platforms like Zillow or Redfin.\n",
    "- Ensure you gather relevant features such as the number of bedrooms, bathrooms, square footage, location (address + pincode) , and price.\n",
    "\n",
    "The scraping is already done using `zillow_chicago_scraper.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/raw/chicago_properties.csv', null_values=['N/A', 'null'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bathrooms and bedrooms are greater than 0\n",
    "df.filter((pl.col('bathrooms') < 1) | (pl.col('bedrooms') < 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Clean and preprocess the data to handle any missing or inconsistent entries.\n",
    "- Encode categorical variables if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find non-numeric price values\n",
    "df.filter(pl.col('price').str.replace('$', '', literal=True).str.replace_all(',', '').cast(pl.Float32, strict=False).is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the price column\n",
    "df = df.with_columns(\n",
    "    pl.col('price')\n",
    "    .replace({'$279,000+': '279000', 'Est. $138.8K': '138800', 'Est. $290K': '290000'})\n",
    "    .str.replace('$', '', literal=True)\n",
    "    .str.replace_all(',', '').cast(pl.Float32)\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the property also matters, let's extract the zip code from the address\n",
    "df = df.with_columns(\n",
    "    pl.col('address')\n",
    "    .str.extract(r'IL (\\d{5})$')\n",
    "    .alias('zip_code')\n",
    ")\n",
    "\n",
    "df['zip_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing zip codes\n",
    "df.filter(pl.col('zip_code').is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing zip code (found using Google Search)\n",
    "df = df.with_columns(\n",
    "    zip_code=pl.when(pl.col('address')==\"Madison FP Plan, Madison\").then(pl.lit('60601')).otherwise(pl.col('zip_code'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter non-numeric unique square footage values\n",
    "df.filter(pl.col('square_footage').cast(pl.Float32, strict=False).is_null())['square_footage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the square footage column, convert unknown values to null\n",
    "df = df.with_columns(\n",
    "    pl.col('square_footage').cast(pl.Float32, strict=False)\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x='bedrooms', y='square_footage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "df.filter(\n",
    "    (((pl.col('square_footage') > 9000) & (pl.col('bedrooms') == 3)) | ((pl.col('square_footage') > 20000) & (pl.col('bedrooms') == 5)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take out these 2 properties which are clearly outliers\n",
    "df = df.filter(\n",
    "    ~pl.col('address').is_in(['1355 N Astor St, Chicago, IL 60610', '415 E North Water St #3205, Chicago, IL 60611'])\n",
    ")\n",
    "\n",
    "px.box(df, x='bedrooms', y='square_footage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x='square_footage', y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed from the scatter plot that a sqaure footage value can have multiple price points, and given other data like bathrooms, bedrooms (categorical data) and zip codes (less data points per state), they do not seem sufficient to explain the price. We need other information like carpet area, house type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x='square_footage', nbins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep these extreme values in the `square_footage` because price is clearly high for them. Because there are few points, it will effect the cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.density_heatmap(df, x='bathrooms', y='bedrooms', z='square_footage', histfunc='avg', title=\"Average square footage by number of bathrooms and bedrooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df.with_columns((pl.count('zip_code').over(['bathrooms', 'bedrooms']) / pl.count('zip_code').over(['bathrooms'])).alias('percentage').round(2)), x='bathrooms', y='bedrooms', size='percentage', title=\"Percentage of bedrooms for bedroom category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "df.select(pl.col('*').is_null().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried imputing bathrooms and square_footage but it did not improve the R2 score. Also, in regression tasks, decision trees are highly sensitive to bias imputation. For reference, here was the code used for imputation:\n",
    "\n",
    "We can first find bathrooms and bedrooms using each other's most common value. Then, we can impute median of square footage based on zipcode, bathroom and bedrooms.\n",
    "\n",
    "```\n",
    "def impute_bedrooms(num_bathrooms):\n",
    "    if num_bathrooms <=2:\n",
    "        return 2\n",
    "    elif num_bathrooms <= 5:\n",
    "        return num_bathrooms\n",
    "    elif num_bathrooms <= 9:\n",
    "        return num_bathrooms - 1\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "# Impute bedrooms\n",
    "df = df.with_columns(\n",
    "    pl.when(\n",
    "        pl.col('bedrooms').is_null()\n",
    "    ).then(\n",
    "        pl.col('bathrooms').map_elements(impute_bedrooms, return_dtype=pl.Float32)\n",
    "    ).otherwise(\n",
    "        pl.col('bedrooms')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Impute square_footage\n",
    "df = df.with_columns(pl.col('square_footage').fill_null(pl.col('square_footage').mean().over(['bedrooms', 'bathrooms', 'zip_code']))).with_columns(pl.col('square_footage').fill_null(pl.col('square_footage').median()))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Decision Tree Model\n",
    "\n",
    "- Use the scraped data to train a decision tree model.\n",
    "- Experiment with different features to see which ones are most predictive of housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from loguru import logger\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "def build_model(model_config=None):\n",
    "    \"\"\"Build a model with the specified configuration\n",
    "\n",
    "    Args:\n",
    "        model_config (dict[str, Any]): Model configuration.\n",
    "\n",
    "    Returns:\n",
    "        object: Model object.\n",
    "    \"\"\"\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    return DecisionTreeRegressor(\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "\n",
    "def train(\n",
    "    X,\n",
    "    y,\n",
    "    model_params=None,\n",
    "    cv=5,  # can also use train-test\n",
    "    metrics=[],\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"Train a model and compute evaluation metrics.\n",
    "\n",
    "    This function is supposed to do four things in order:\n",
    "    1. Perform training along with the validation setup.\n",
    "    2. Evaluate the model on specified metrics.\n",
    "    3. Retrain the model on the full dataset.\n",
    "    4. Save the model if a path is provided.\n",
    "\n",
    "    Args:\n",
    "        X (DataFrame): Features.\n",
    "        y (DataFrame): Labels.\n",
    "        model_params: Model parameters.\n",
    "        cv (int, optional): Number of cross-validation folds. Defaults to 5.\n",
    "        eval_metrics (list, optional): Evaluation metrics to compute. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        object: Trained model.\n",
    "        np.ndarray: Out-of-fold predictions.\n",
    "        dict: Evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Perform CV\n",
    "    kf = KFold(cv, random_state=random_state, shuffle=True)\n",
    "    scorers = {metric: get_scorer(metric)._score_func for metric in metrics}\n",
    "\n",
    "    train_scores = {metric: [] for metric in metrics}\n",
    "    valid_scores = {metric: [] for metric in metrics}\n",
    "    oof_preds = np.zeros(len(y), dtype=int)\n",
    "    models = []\n",
    "    for fold, (tridx, validx) in enumerate(kf.split(X, y)):\n",
    "        model_ = build_model(model_params)\n",
    "\n",
    "        X_train, y_train = X[list(tridx)], y[list(tridx)]\n",
    "        X_valid, y_valid = X[list(validx)], y[list(validx)]\n",
    "\n",
    "        # Train model\n",
    "        model_.fit(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
    "        models.append(model_)\n",
    "\n",
    "        # Predict on test dataset\n",
    "        y_pred = model_.predict(X_valid.to_numpy())\n",
    "        oof_preds[validx] = y_pred\n",
    "\n",
    "        for metric in metrics:\n",
    "            valid_score = scorers[metric](y_valid.to_numpy().ravel(), y_pred)\n",
    "            valid_scores[metric].append(valid_score)\n",
    "\n",
    "            train_score = scorers[metric](\n",
    "                y_train.to_numpy().ravel(),\n",
    "                model_.predict(X_train.to_numpy()),\n",
    "            )\n",
    "            train_scores[metric].append(train_score)\n",
    "\n",
    "            logger.info(\n",
    "                f\"Fold: {fold+1}/{cv}, Train {metric}: {train_score}, Valid {metric}: {valid_score}\"\n",
    "            )\n",
    "\n",
    "    # Compute CV mean and standard deviation of train and valid scores\n",
    "    cv_mean_train_scores = {\n",
    "        metric: np.mean(train_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_std_train_scores = {\n",
    "        metric: np.std(train_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_mean_valid_scores = {\n",
    "        metric: np.mean(valid_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_std_valid_scores = {\n",
    "        metric: np.std(valid_scores[metric]) for metric in metrics\n",
    "    }\n",
    "\n",
    "    # Compute OOF scores\n",
    "    oof_score = {metric: scorers[metric](y, oof_preds) for metric in metrics}\n",
    "\n",
    "    evaluation_metrics = {\n",
    "        \"CV Mean Train score\": cv_mean_train_scores,\n",
    "        \"CV Std Train score\": cv_std_train_scores,\n",
    "        \"CV Mean Valid score\": cv_mean_valid_scores,\n",
    "        \"CV Std Valid score\": cv_std_valid_scores,\n",
    "        \"OOF Score\": oof_score,\n",
    "    }\n",
    "\n",
    "    # Retrain model on full dataset\n",
    "    model = build_model(model_params)\n",
    "    model.fit(X.to_numpy(), y.to_numpy().ravel())\n",
    "\n",
    "    return model, oof_preds, evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode zip code\n",
    "X = df.to_dummies('zip_code')\n",
    "\n",
    "# Feature engineering\n",
    "X = X.with_columns(\n",
    "    (pl.col('bedrooms') + pl.col('bathrooms')).alias('B_plus_B'),\n",
    "    (pl.col('bedrooms') * pl.col('bathrooms')).alias('B_prod_B'),\n",
    "    (pl.col('square_footage') / pl.col('bedrooms')).alias('sq_div_bed'),\n",
    "    (pl.col('square_footage') / pl.col('bathrooms')).alias('sq_div_bath'),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "feature_cols = ['bedrooms', 'bathrooms', 'square_footage'] + [col for col in X.columns if col.startswith('zip_code')] + ['B_plus_B', 'B_prod_B', 'sq_div_bed', 'sq_div_bath']\n",
    "target_col = 'price'\n",
    "\n",
    "model, oof_preds, evaluation_results = train(\n",
    "    X=X[feature_cols],\n",
    "    y=df[target_col],\n",
    "    cv=5,\n",
    "    metrics=['neg_mean_squared_error', 'neg_root_mean_squared_error', 'r2'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Reporting\n",
    "\n",
    "- Analyze the results of your decision tree model.\n",
    "- Discuss the features that were most influential in predicting housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(x=df[target_col], y=oof_preds, labels={'x': 'Ground Truth - Price', 'y': 'Predicted - Price'})\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df[target_col], y=df[target_col], name=\"linear\", line_shape='linear')\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = sorted(list(zip(X[feature_cols].columns, model.feature_importances_)), key=lambda x: x[1], reverse=True)\n",
    "feature_importances_X = [x[0] for x in feature_importances if x[1] > 0]\n",
    "feature_importances_y = [x[1] for x in feature_importances if x[1] > 0]\n",
    "\n",
    "px.bar(x=feature_importances_X, y=feature_importances_y, labels={'x': 'Feature', 'y': 'Importance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sq_div_bed` i.e. = (Square footage / Number of bedrooms) and number of `bathrooms` are the most important determining factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
