{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from rich import print\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import get_scorer\n",
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../data/raw/chicago_properties.csv', null_values=['N/A', 'null'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the price column\n",
    "df = df.with_columns(\n",
    "    pl.col('price')\n",
    "    .replace({'$279,000+': '279000', 'Est. $138.8K': '138800', 'Est. $290K': '290000'})\n",
    "    .str.replace('$', '', literal=True)\n",
    "    .str.replace_all(',', '').cast(pl.Float32)\n",
    ")\n",
    "\n",
    "# Location of the property also matters, let's extract the zip code from the address\n",
    "df = df.with_columns(\n",
    "    pl.col('address')\n",
    "    .str.extract(r'IL (\\d{5})$')\n",
    "    .alias('zipcode')\n",
    ")\n",
    "\n",
    "# Fill in the missing zip code (found using Google Search)\n",
    "df = df.with_columns(\n",
    "    zipcode=pl.when(pl.col('address')==\"Madison FP Plan, Madison\").then(pl.lit('60601')).otherwise(pl.col('zipcode'))\n",
    ")\n",
    "\n",
    "# Clean the square footage column, convert unknown values to null\n",
    "df = df.with_columns(\n",
    "    pl.col('square_footage').cast(pl.Float32, strict=False)\n",
    ")\n",
    "\n",
    "# Remove outliers\n",
    "df = df.filter(\n",
    "    ~pl.col('address').is_in([\n",
    "        '1355 N Astor St, Chicago, IL 60610',\n",
    "        '415 E North Water St #3205, Chicago, IL 60611'\n",
    "    ]) # extremely high sq ft given less number of bedrooms\n",
    ").filter(\n",
    "    pl.col('zipcode') != '60602' # missing bedrooms for all properties in this zip code (2 rows)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_params={}):\n",
    "    \"\"\"Build a model with the specified configuration\n",
    "\n",
    "    Args:\n",
    "        model_config (dict[str, Any]): Model configuration.\n",
    "\n",
    "    Returns:\n",
    "        object: Model object.\n",
    "    \"\"\"\n",
    "    return XGBRFRegressor(**model_params, random_state=42)\n",
    "    # return DecisionTreeRegressor(\n",
    "    #     max_depth=16,\n",
    "    #     min_samples_leaf=5,\n",
    "    #     random_state=42,\n",
    "    # )\n",
    "\n",
    "\n",
    "def train(\n",
    "    X,\n",
    "    y,\n",
    "    model_params={},\n",
    "    cv=5,  # can also use train-test\n",
    "    metrics=[],\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"Train a model and compute evaluation metrics.\n",
    "\n",
    "    This function is supposed to do four things in order:\n",
    "    1. Perform training along with the validation setup.\n",
    "    2. Evaluate the model on specified metrics.\n",
    "    3. Retrain the model on the full dataset.\n",
    "    4. Save the model if a path is provided.\n",
    "\n",
    "    Args:\n",
    "        X (DataFrame): Features.\n",
    "        y (DataFrame): Labels.\n",
    "        model_params: Model parameters.\n",
    "        cv (int, optional): Number of cross-validation folds. Defaults to 5.\n",
    "        eval_metrics (list, optional): Evaluation metrics to compute. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        object: Trained model.\n",
    "        np.ndarray: Out-of-fold predictions.\n",
    "        dict: Evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Perform CV\n",
    "    kf = KFold(cv)\n",
    "    scorers = {metric: get_scorer(metric)._score_func for metric in metrics}\n",
    "\n",
    "    train_scores = {metric: [] for metric in metrics}\n",
    "    valid_scores = {metric: [] for metric in metrics}\n",
    "    oof_preds = np.zeros(len(y), dtype=int)\n",
    "    models = []\n",
    "    for fold, (tridx, validx) in enumerate(kf.split(X, y)):\n",
    "        model_ = build_model(model_params)\n",
    "\n",
    "        X_train, y_train = X[list(tridx)], y[list(tridx)]\n",
    "        X_valid, y_valid = X[list(validx)], y[list(validx)]\n",
    "\n",
    "        from sklearn.preprocessing import QuantileTransformer\n",
    "        qtr = QuantileTransformer(n_quantiles=100)\n",
    "        transformed_sq_footage = qtr.fit_transform(X_train['square_footage'].to_numpy().reshape(-1, 1))\n",
    "        X_train = X_train.with_columns(square_footage=transformed_sq_footage)\n",
    "        X_valid = X_valid.with_columns(square_footage=qtr.transform(X_valid['square_footage'].to_numpy().reshape(-1, 1)))\n",
    "\n",
    "        # Train model\n",
    "        # set sample weight 2 for properties having square footage more than 5000 else 1\n",
    "        # sample_weight = np.where(X_train['square_footage'] > 5000, 5, 1)\n",
    "        # model_.fit(X_train.to_numpy(), y_train.to_numpy().ravel(), sample_weight=sample_weight)\n",
    "        model_.fit(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
    "        models.append(model_)\n",
    "\n",
    "        # Predict on test dataset\n",
    "        y_pred = model_.predict(X_valid.to_numpy())\n",
    "        oof_preds[validx] = y_pred\n",
    "\n",
    "        for metric in metrics:\n",
    "            valid_score = scorers[metric](y_valid.to_numpy().ravel(), y_pred)\n",
    "            valid_scores[metric].append(valid_score)\n",
    "\n",
    "            train_score = scorers[metric](\n",
    "                y_train.to_numpy().ravel(),\n",
    "                model_.predict(X_train.to_numpy()),\n",
    "            )\n",
    "            train_scores[metric].append(train_score)\n",
    "\n",
    "            # print(f\"Fold: {fold+1}/{cv}, Train {metric}: {train_score:.3f}, Valid {metric}: {valid_score:.3f}\")\n",
    "\n",
    "    # Compute CV mean and standard deviation of train and valid scores\n",
    "    cv_mean_train_scores = {\n",
    "        metric: np.mean(train_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_std_train_scores = {\n",
    "        metric: np.std(train_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_mean_valid_scores = {\n",
    "        metric: np.mean(valid_scores[metric]) for metric in metrics\n",
    "    }\n",
    "    cv_std_valid_scores = {\n",
    "        metric: np.std(valid_scores[metric]) for metric in metrics\n",
    "    }\n",
    "\n",
    "    # Compute OOF scores\n",
    "    oof_score = {metric: scorers[metric](y, oof_preds) for metric in metrics}\n",
    "\n",
    "    # Compute metrics on average of all models\n",
    "    evaluation_metrics = {\n",
    "        \"CV Mean Train score\": cv_mean_train_scores,\n",
    "        \"CV Std Train score\": cv_std_train_scores,\n",
    "        \"CV Mean Valid score\": cv_mean_valid_scores,\n",
    "        \"CV Std Valid score\": cv_std_valid_scores,\n",
    "        \"OOF Score\": oof_score,\n",
    "    }\n",
    "\n",
    "    return models, oof_preds, evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "X = df.with_columns(\n",
    "    (pl.col('bedrooms') + pl.col('bathrooms')).alias('B_plus_B'),\n",
    "    (pl.col('bedrooms') * pl.col('bathrooms')).alias('B_prod_B'),\n",
    "    (pl.col('bedrooms') / pl.col('bathrooms')).alias('B_div_B'),\n",
    "    (pl.col('square_footage') / pl.col('bedrooms')).alias('sq_div_bed'),\n",
    "    (pl.col('square_footage') / pl.col('bathrooms')).alias('sq_div_bath'),\n",
    "    (pl.col('square_footage').median().over('zipcode')).alias('median_sq_ft_zipcode'),\n",
    "    (pl.col('square_footage').mean().over('zipcode')).alias('mean_sq_ft_zipcode'),\n",
    "    (pl.col('square_footage').std().over('zipcode')).alias('std_sq_ft_zipcode'),\n",
    "    (pl.col('square_footage').min().over('zipcode')).alias('min_sq_ft_zipcode'),\n",
    "    (pl.col('square_footage').max().over('zipcode')).alias('max_sq_ft_zipcode'),\n",
    "    (pl.col('price').median().over('zipcode')).alias('median_price_zipcode'),\n",
    "    (pl.col('price').mean().over('zipcode')).alias('mean_price_zipcode'),\n",
    "    (pl.col('price').std().over('zipcode')).alias('std_price_zipcode'),\n",
    "    (pl.col('price').min().over('zipcode')).alias('min_price_zipcode'),\n",
    "    (pl.col('price').max().over('zipcode')).alias('max_price_zipcode'),\n",
    "    ((pl.col('price') / pl.col('square_footage')).median().over('zipcode')).alias('median_price_per_sq_ft_zipcode'),\n",
    "    ((pl.col('price') / pl.col('square_footage')).mean().over('zipcode')).alias('mean_price_per_sq_ft_zipcode'),\n",
    "    ((pl.col('price') / pl.col('square_footage')).std().over('zipcode')).alias('std_price_per_sq_ft_zipcode'),\n",
    "    ((pl.col('price') / pl.col('square_footage')).min().over('zipcode')).alias('min_price_per_sq_ft_zipcode'),\n",
    "    ((pl.col('price') / pl.col('square_footage')).max().over('zipcode')).alias('max_price_per_sq_ft_zipcode'),\n",
    ")\n",
    "\n",
    "# One hot encode zip code\n",
    "# X.drop_in_place('zipcode')\n",
    "X = X.to_dummies('zipcode')\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = (\n",
    "    ['bedrooms', 'bathrooms', 'square_footage']\n",
    "      + [col for col in X.columns if col.startswith('zipcode')]\n",
    "        + ['B_plus_B', 'B_prod_B', 'B_div_B', 'sq_div_bed', 'sq_div_bath',\n",
    "            'median_sq_ft_zipcode', 'mean_sq_ft_zipcode', 'std_sq_ft_zipcode', 'min_sq_ft_zipcode', 'max_sq_ft_zipcode',\n",
    "            'median_price_zipcode', 'mean_price_zipcode', 'std_price_zipcode', 'min_price_zipcode', 'max_price_zipcode',\n",
    "            'median_price_per_sq_ft_zipcode', 'mean_price_per_sq_ft_zipcode', 'std_price_per_sq_ft_zipcode', 'min_price_per_sq_ft_zipcode', 'max_price_per_sq_ft_zipcode'])\n",
    "\n",
    "target_col = 'price'\n",
    "\n",
    "xgb_params = {\n",
    "    'alpha': 13,\n",
    "    'eta': 0.7,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.5\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "models, oof_preds, evaluation_results = train(\n",
    "    X=X[feature_cols],\n",
    "    y=df[target_col],\n",
    "    cv=5,\n",
    "    model_params=xgb_params,\n",
    "    metrics=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=df[target_col], y=oof_preds, labels={'x': 'Ground Truth - Price', 'y': 'Predicted - Price'})\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df[target_col], y=df[target_col], name=\"linear\", line_shape='linear')\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances = sorted(list(zip(X[feature_cols].columns, np.mean([model.feature_importances_ for model in models], axis=0))), key=lambda x: x[1], reverse=True)\n",
    "feature_importances_X = [x[0] for x in feature_importances if x[1] > 0][:20]\n",
    "feature_importances_y = [x[1] for x in feature_importances if x[1] > 0][:20]\n",
    "\n",
    "px.bar(x=feature_importances_X, y=feature_importances_y, labels={'x': 'Feature', 'y': 'Importance'}, title=\"Top 20 features by importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hypertune decision tree\n",
    "    model_params = {\n",
    "        'alpha': trial.suggest_int('alpha', 0.0, 20.0),\n",
    "        'eta': 0.7,\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        'subsample': 0.5\n",
    "    }\n",
    "\n",
    "    _, _, metrics = train(\n",
    "        X=X[feature_cols],\n",
    "        y=df[target_col],\n",
    "        model_params=model_params,\n",
    "        cv=5,\n",
    "        metrics=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
    "    )\n",
    "    return metrics['OOF Score']['r2']\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_slice\n",
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
